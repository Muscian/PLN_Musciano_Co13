{"cells":[{"cell_type":"markdown","metadata":{"id":"pfa39F4lsLf3"},"source":["<img src=\"https://github.com/hernancontigiani/ceia_memorias_especializacion/raw/master/Figures/logoFIUBA.jpg\" width=\"500\" align=\"center\">\n","\n","\n","# Procesamiento de lenguaje natural\n","## LSTM Bot QA"]},{"cell_type":"markdown","metadata":{"id":"ZqO0PRcFsPTe"},"source":["### Datos\n","El objecto es utilizar datos disponibles del challenge ConvAI2 (Conversational Intelligence Challenge 2) de conversaciones en inglés. Se construirá un BOT para responder a preguntas del usuario (QA).\\\n","[LINK](http://convai.io/data/)"]},{"cell_type":"code","execution_count":25,"metadata":{"id":"bDFC0I3j9oFD"},"outputs":[{"name":"stderr","output_type":"stream","text":["\n","[notice] A new release of pip available: 22.2.1 -> 24.1\n","[notice] To update, run: python.exe -m pip install --upgrade pip\n"]}],"source":["!pip install --upgrade --no-cache-dir gdown --quiet"]},{"cell_type":"code","execution_count":26,"metadata":{"id":"cq3YXak9sGHd"},"outputs":[],"source":["import re\n","\n","import numpy as np\n","import pandas as pd\n","\n","import tensorflow as tf\n","from tensorflow.keras.preprocessing.text import one_hot\n","from tensorflow.keras.utils import pad_sequences\n","from keras.models import Sequential\n","from keras.layers import Activation, Dropout, Dense\n","from keras.layers import Flatten, LSTM, SimpleRNN\n","from keras.models import Model\n","from tensorflow.keras.layers import Embedding\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from keras.layers import Input\n","from tensorflow.keras.models import load_model"]},{"cell_type":"code","execution_count":27,"metadata":{"id":"RHNkUaPp6aYq"},"outputs":[{"name":"stdout","output_type":"stream","text":["El dataset ya se encuentra descargado\n"]}],"source":["# Descargar la carpeta de dataset\n","import os\n","import gdown\n","if os.access('data_volunteers.json', os.F_OK) is False:\n","    url = 'https://drive.google.com/uc?id=1awUxYwImF84MIT5-jCaYAPe2QwSgS1hN&export=download'\n","    output = 'data_volunteers.json'\n","    gdown.download(url, output, quiet=False)\n","else:\n","    print(\"El dataset ya se encuentra descargado\")"]},{"cell_type":"code","execution_count":28,"metadata":{"id":"WZy1-wgG-Rp7"},"outputs":[],"source":["# dataset_file\n","import json\n","\n","text_file = \"data_volunteers.json\"\n","with open(text_file) as f:\n","    data = json.load(f) # la variable data será un diccionario\n","\n"]},{"cell_type":"code","execution_count":29,"metadata":{"id":"ue5qd54S-eew"},"outputs":[{"data":{"text/plain":["dict_keys(['dialog', 'start_time', 'end_time', 'bot_profile', 'user_profile', 'eval_score', 'profile_match', 'participant1_id', 'participant2_id'])"]},"execution_count":29,"metadata":{},"output_type":"execute_result"}],"source":["# Observar los campos disponibles en cada linea del dataset\n","data[0].keys()"]},{"cell_type":"code","execution_count":30,"metadata":{"id":"jHBRAXPl-3dz"},"outputs":[{"name":"stdout","output_type":"stream","text":["Cantidad de rows utilizadas: 6033\n"]}],"source":["chat_in = []\n","chat_out = []\n","\n","input_sentences = []\n","output_sentences = []\n","output_sentences_inputs = []\n","max_len = 30\n","\n","def clean_text(txt):\n","    txt = txt.lower()    \n","    txt.replace(\"\\'d\", \" had\")\n","    txt.replace(\"\\'s\", \" is\")\n","    txt.replace(\"\\'m\", \" am\")\n","    txt.replace(\"don't\", \"do not\")\n","    txt = re.sub(r'\\W+', ' ', txt)\n","    \n","    return txt\n","\n","for line in data:\n","    for i in range(len(line['dialog'])-1):\n","        # vamos separando el texto en \"preguntas\" (chat_in)\n","        # y \"respuestas\" (chat_out)\n","        chat_in = clean_text(line['dialog'][i]['text'])\n","        chat_out = clean_text(line['dialog'][i+1]['text'])\n","\n","        if len(chat_in) >= max_len or len(chat_out) >= max_len:\n","            continue\n","\n","        input_sentence, output = chat_in, chat_out\n","        \n","        # output sentence (decoder_output) tiene <eos>\n","        output_sentence = output + ' <eos>'\n","        # output sentence input (decoder_input) tiene <sos>\n","        output_sentence_input = '<sos> ' + output\n","\n","        input_sentences.append(input_sentence)\n","        output_sentences.append(output_sentence)\n","        output_sentences_inputs.append(output_sentence_input)\n","\n","print(\"Cantidad de rows utilizadas:\", len(input_sentences))"]},{"cell_type":"code","execution_count":31,"metadata":{"id":"07L1qj8pC_l6"},"outputs":[{"data":{"text/plain":["('hi how are you ', 'not bad and you  <eos>', '<sos> not bad and you ')"]},"execution_count":31,"metadata":{},"output_type":"execute_result"}],"source":["input_sentences[1], output_sentences[1], output_sentences_inputs[1]"]},{"cell_type":"markdown","metadata":{"id":"8P-ynUNP5xp6"},"source":["### 2 - Preprocesamiento\n","Realizar el preprocesamiento necesario para obtener:\n","- word2idx_inputs, max_input_len\n","- word2idx_outputs, max_out_len, num_words_output\n","- encoder_input_sequences, decoder_output_sequences, decoder_targets"]},{"cell_type":"code","execution_count":48,"metadata":{},"outputs":[],"source":["# Tokenizar las oraciones de entrada\n","tokenizer_inputs = Tokenizer()\n","tokenizer_inputs.fit_on_texts(input_sentences)\n","input_sequences = tokenizer_inputs.texts_to_sequences(input_sentences)\n","\n","# Longitud máxima de las secuencias de entrada\n","max_input_len = max(len(seq) for seq in input_sequences)\n","\n","# Crear word2idx para las entradas\n","word2idx_inputs = tokenizer_inputs.word_index\n","num_words_input = len(word2idx_inputs) + 1\n","\n","# Tokenizar las oraciones de salida\n","tokenizer_outputs = Tokenizer()\n","tokenizer_outputs.fit_on_texts(output_sentences + output_sentences_inputs)\n","output_sequences = tokenizer_outputs.texts_to_sequences(output_sentences)\n","output_sequences_inputs = tokenizer_outputs.texts_to_sequences(output_sentences_inputs)\n","\n","# Longitud máxima de las secuencias de salida\n","max_output_len = max(len(seq) for seq in output_sequences)\n","\n","# Añadir tokens especiales a las oraciones de salida durante la tokenización\n","tokenizer_outputs = Tokenizer(filters='')\n","tokenizer_outputs.fit_on_texts(output_sentences + output_sentences_inputs)\n","output_sequences = tokenizer_outputs.texts_to_sequences(output_sentences)\n","output_sequences_inputs = tokenizer_outputs.texts_to_sequences(output_sentences_inputs)\n","\n","# Crear word2idx para las salidas\n","word2idx_outputs = tokenizer_outputs.word_index\n","word2idx_outputs['<sos>'] = tokenizer_outputs.word_index.get('<sos>', len(word2idx_outputs) + 1)\n","word2idx_outputs['<eos>'] = tokenizer_outputs.word_index.get('<eos>', len(word2idx_outputs) + 1)\n","num_words_output = len(word2idx_outputs) + 1\n","\n","# Padding de las secuencias\n","encoder_input_sequences = pad_sequences(input_sequences, maxlen=max_input_len)\n","decoder_input_sequences = pad_sequences(output_sequences_inputs, maxlen=max_output_len)\n","decoder_output_sequences = pad_sequences(output_sequences, maxlen=max_output_len)\n"]},{"cell_type":"markdown","metadata":{"id":"_CJIsLBbj6rg"},"source":["### 3 - Preparar los embeddings\n","Utilizar los embeddings de Glove o FastText para transformar los tokens de entrada en vectores"]},{"cell_type":"code","execution_count":39,"metadata":{},"outputs":[],"source":["# Suponiendo que estás usando el archivo GloVe de 300 dimensiones\n","embedding_dim = 300\n","\n","# Cargar embeddings preentrenados (GloVe de 300 dimensiones)\n","embeddings_index = {}\n","with open('data/d4/glove_embeddings.txt', 'r', encoding='utf-8') as f:\n","    for line in f:\n","        values = line.split()\n","        word = values[0]\n","        coefs = np.asarray(values[1:], dtype='float32')\n","        embeddings_index[word] = coefs\n","\n","# Crear matriz de embedding para entradas\n","embedding_matrix_input = np.zeros((num_words_input, embedding_dim))\n","for word, i in word2idx_inputs.items():\n","    embedding_vector = embeddings_index.get(word)\n","    if embedding_vector is not None:\n","        embedding_matrix_input[i] = embedding_vector\n","\n","# Crear matriz de embedding para salidas\n","embedding_matrix_output = np.zeros((num_words_output, embedding_dim))\n","for word, i in word2idx_outputs.items():\n","    embedding_vector = embeddings_index.get(word)\n","    if embedding_vector is not None:\n","        embedding_matrix_output[i] = embedding_vector\n"]},{"cell_type":"markdown","metadata":{"id":"3vKbhjtIwPgM"},"source":["### 4 - Entrenar el modelo\n","Entrenar un modelo basado en el esquema encoder-decoder utilizando los datos generados en los puntos anteriores. Utilce como referencias los ejemplos vistos en clase."]},{"cell_type":"code","execution_count":40,"metadata":{},"outputs":[],"source":["# Crear el modelo encoder\n","encoder_inputs = Input(shape=(max_input_len,))\n","encoder_embedding = Embedding(num_words_input, embedding_dim, weights=[embedding_matrix_input], trainable=False)(encoder_inputs)\n","encoder_lstm = LSTM(256, return_state=True)\n","encoder_outputs, state_h, state_c = encoder_lstm(encoder_embedding)\n","encoder_states = [state_h, state_c]\n","\n","# Crear el modelo decoder\n","decoder_inputs = Input(shape=(max_output_len,))\n","decoder_embedding = Embedding(num_words_output, embedding_dim, weights=[embedding_matrix_output], trainable=False)(decoder_inputs)\n","decoder_lstm = LSTM(256, return_sequences=True, return_state=True)\n","decoder_outputs, _, _ = decoder_lstm(decoder_embedding, initial_state=encoder_states)\n","decoder_dense = Dense(num_words_output, activation='softmax')\n","decoder_outputs = decoder_dense(decoder_outputs)\n","\n","# Definir el modelo\n","model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n","\n","# Compilar el modelo\n","model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')\n"]},{"cell_type":"code","execution_count":41,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/100\n","\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 62ms/step - loss: 4.2279 - val_loss: 2.0300\n","Epoch 2/100\n","\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 61ms/step - loss: 1.7790 - val_loss: 1.7488\n","Epoch 3/100\n","\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 59ms/step - loss: 1.4610 - val_loss: 1.6125\n","Epoch 4/100\n","\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 59ms/step - loss: 1.3477 - val_loss: 1.5476\n","Epoch 5/100\n","\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 58ms/step - loss: 1.2280 - val_loss: 1.5078\n","Epoch 6/100\n","\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 58ms/step - loss: 1.1837 - val_loss: 1.4761\n","Epoch 7/100\n","\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 58ms/step - loss: 1.1255 - val_loss: 1.4562\n","Epoch 8/100\n","\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 57ms/step - loss: 1.0839 - val_loss: 1.4430\n","Epoch 9/100\n","\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 58ms/step - loss: 1.0514 - val_loss: 1.4287\n","Epoch 10/100\n","\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 58ms/step - loss: 0.9945 - val_loss: 1.4130\n","Epoch 11/100\n","\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - loss: 0.9812 - val_loss: 1.4041\n","Epoch 12/100\n","\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - loss: 0.9287 - val_loss: 1.3948\n","Epoch 13/100\n","\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 59ms/step - loss: 0.9197 - val_loss: 1.3920\n","Epoch 14/100\n","\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 61ms/step - loss: 0.8875 - val_loss: 1.3936\n","Epoch 15/100\n","\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 59ms/step - loss: 0.8414 - val_loss: 1.3856\n","Epoch 16/100\n","\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 58ms/step - loss: 0.8356 - val_loss: 1.3873\n","Epoch 17/100\n","\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 58ms/step - loss: 0.8127 - val_loss: 1.3863\n","Epoch 18/100\n","\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - loss: 0.7854 - val_loss: 1.3843\n","Epoch 19/100\n","\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 59ms/step - loss: 0.7639 - val_loss: 1.3902\n","Epoch 20/100\n","\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 59ms/step - loss: 0.7449 - val_loss: 1.3885\n","Epoch 21/100\n","\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 59ms/step - loss: 0.7223 - val_loss: 1.3988\n","Epoch 22/100\n","\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 59ms/step - loss: 0.7159 - val_loss: 1.3970\n","Epoch 23/100\n","\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 59ms/step - loss: 0.6992 - val_loss: 1.3965\n","Epoch 24/100\n","\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - loss: 0.6692 - val_loss: 1.4061\n","Epoch 25/100\n","\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - loss: 0.6656 - val_loss: 1.4062\n","Epoch 26/100\n","\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 59ms/step - loss: 0.6400 - val_loss: 1.4131\n","Epoch 27/100\n","\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - loss: 0.6319 - val_loss: 1.4123\n","Epoch 28/100\n","\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 59ms/step - loss: 0.6074 - val_loss: 1.4119\n","Epoch 29/100\n","\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 59ms/step - loss: 0.5934 - val_loss: 1.4234\n","Epoch 30/100\n","\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 59ms/step - loss: 0.5882 - val_loss: 1.4214\n","Epoch 31/100\n","\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - loss: 0.5761 - val_loss: 1.4337\n","Epoch 32/100\n","\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - loss: 0.5690 - val_loss: 1.4346\n","Epoch 33/100\n","\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 59ms/step - loss: 0.5575 - val_loss: 1.4400\n","Epoch 34/100\n","\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 62ms/step - loss: 0.5402 - val_loss: 1.4416\n","Epoch 35/100\n","\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 62ms/step - loss: 0.5368 - val_loss: 1.4531\n","Epoch 36/100\n","\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 59ms/step - loss: 0.5100 - val_loss: 1.4511\n","Epoch 37/100\n","\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - loss: 0.5016 - val_loss: 1.4611\n","Epoch 38/100\n","\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 59ms/step - loss: 0.5036 - val_loss: 1.4755\n","Epoch 39/100\n","\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 59ms/step - loss: 0.4908 - val_loss: 1.4763\n","Epoch 40/100\n","\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 58ms/step - loss: 0.4746 - val_loss: 1.4882\n","Epoch 41/100\n","\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 59ms/step - loss: 0.4673 - val_loss: 1.4905\n","Epoch 42/100\n","\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 59ms/step - loss: 0.4606 - val_loss: 1.4936\n","Epoch 43/100\n","\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - loss: 0.4386 - val_loss: 1.4967\n","Epoch 44/100\n","\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 59ms/step - loss: 0.4371 - val_loss: 1.5117\n","Epoch 45/100\n","\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 59ms/step - loss: 0.4231 - val_loss: 1.5194\n","Epoch 46/100\n","\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 59ms/step - loss: 0.4162 - val_loss: 1.5190\n","Epoch 47/100\n","\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - loss: 0.3982 - val_loss: 1.5246\n","Epoch 48/100\n","\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - loss: 0.3935 - val_loss: 1.5421\n","Epoch 49/100\n","\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 59ms/step - loss: 0.3904 - val_loss: 1.5544\n","Epoch 50/100\n","\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 59ms/step - loss: 0.3804 - val_loss: 1.5525\n","Epoch 51/100\n","\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 59ms/step - loss: 0.3633 - val_loss: 1.5644\n","Epoch 52/100\n","\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 59ms/step - loss: 0.3634 - val_loss: 1.5766\n","Epoch 53/100\n","\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - loss: 0.3473 - val_loss: 1.5843\n","Epoch 54/100\n","\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 59ms/step - loss: 0.3457 - val_loss: 1.5882\n","Epoch 55/100\n","\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - loss: 0.3384 - val_loss: 1.5935\n","Epoch 56/100\n","\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 59ms/step - loss: 0.3261 - val_loss: 1.6082\n","Epoch 57/100\n","\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 59ms/step - loss: 0.3142 - val_loss: 1.5992\n","Epoch 58/100\n","\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 58ms/step - loss: 0.3072 - val_loss: 1.6165\n","Epoch 59/100\n","\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 59ms/step - loss: 0.2974 - val_loss: 1.6299\n","Epoch 60/100\n","\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - loss: 0.2918 - val_loss: 1.6346\n","Epoch 61/100\n","\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 59ms/step - loss: 0.2858 - val_loss: 1.6425\n","Epoch 62/100\n","\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - loss: 0.2775 - val_loss: 1.6539\n","Epoch 63/100\n","\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - loss: 0.2719 - val_loss: 1.6607\n","Epoch 64/100\n","\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - loss: 0.2623 - val_loss: 1.6562\n","Epoch 65/100\n","\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 59ms/step - loss: 0.2540 - val_loss: 1.6791\n","Epoch 66/100\n","\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 59ms/step - loss: 0.2443 - val_loss: 1.6802\n","Epoch 67/100\n","\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 0.2443 - val_loss: 1.6991\n","Epoch 68/100\n","\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 0.2342 - val_loss: 1.7074\n","Epoch 69/100\n","\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 63ms/step - loss: 0.2293 - val_loss: 1.7141\n","Epoch 70/100\n","\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 64ms/step - loss: 0.2195 - val_loss: 1.7192\n","Epoch 71/100\n","\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 0.2137 - val_loss: 1.7348\n","Epoch 72/100\n","\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 61ms/step - loss: 0.2107 - val_loss: 1.7427\n","Epoch 73/100\n","\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 63ms/step - loss: 0.2078 - val_loss: 1.7485\n","Epoch 74/100\n","\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 62ms/step - loss: 0.1999 - val_loss: 1.7609\n","Epoch 75/100\n","\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 63ms/step - loss: 0.1959 - val_loss: 1.7715\n","Epoch 76/100\n","\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 64ms/step - loss: 0.1930 - val_loss: 1.7785\n","Epoch 77/100\n","\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 0.1841 - val_loss: 1.7922\n","Epoch 78/100\n","\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 0.1812 - val_loss: 1.7978\n","Epoch 79/100\n","\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 63ms/step - loss: 0.1747 - val_loss: 1.8015\n","Epoch 80/100\n","\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - loss: 0.1694 - val_loss: 1.8159\n","Epoch 81/100\n","\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 58ms/step - loss: 0.1651 - val_loss: 1.8217\n","Epoch 82/100\n","\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - loss: 0.1618 - val_loss: 1.8355\n","Epoch 83/100\n","\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 61ms/step - loss: 0.1612 - val_loss: 1.8456\n","Epoch 84/100\n","\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 59ms/step - loss: 0.1589 - val_loss: 1.8431\n","Epoch 85/100\n","\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - loss: 0.1540 - val_loss: 1.8617\n","Epoch 86/100\n","\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 59ms/step - loss: 0.1480 - val_loss: 1.8633\n","Epoch 87/100\n","\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - loss: 0.1421 - val_loss: 1.8705\n","Epoch 88/100\n","\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 58ms/step - loss: 0.1471 - val_loss: 1.8872\n","Epoch 89/100\n","\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - loss: 0.1403 - val_loss: 1.8996\n","Epoch 90/100\n","\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 59ms/step - loss: 0.1379 - val_loss: 1.9163\n","Epoch 91/100\n","\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - loss: 0.1380 - val_loss: 1.9078\n","Epoch 92/100\n","\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - loss: 0.1323 - val_loss: 1.9164\n","Epoch 93/100\n","\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 59ms/step - loss: 0.1276 - val_loss: 1.9226\n","Epoch 94/100\n","\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - loss: 0.1302 - val_loss: 1.9445\n","Epoch 95/100\n","\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 59ms/step - loss: 0.1310 - val_loss: 1.9439\n","Epoch 96/100\n","\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 62ms/step - loss: 0.1270 - val_loss: 1.9447\n","Epoch 97/100\n","\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - loss: 0.1263 - val_loss: 1.9594\n","Epoch 98/100\n","\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 61ms/step - loss: 0.1234 - val_loss: 1.9628\n","Epoch 99/100\n","\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 63ms/step - loss: 0.1199 - val_loss: 1.9767\n","Epoch 100/100\n","\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 62ms/step - loss: 0.1163 - val_loss: 1.9860\n"]}],"source":["# Convertir las secuencias de salida en una forma compatible para entrenamiento\n","decoder_output_sequences = np.expand_dims(decoder_output_sequences, -1)\n","\n","# Entrenar el modelo\n","model.fit([encoder_input_sequences, decoder_input_sequences], decoder_output_sequences, batch_size=64, epochs=100, validation_split=0.2)\n","# Guardar el modelo completo\n","model.save('models/chatbot_model.keras')\n","\n"]},{"cell_type":"markdown","metadata":{"id":"Zbwn0ekDy_s2"},"source":["### 5 - Inferencia\n","Experimentar el funcionamiento de su modelo. Recuerde que debe realizar la inferencia de los modelos por separado de encoder y decoder."]},{"cell_type":"code","execution_count":46,"metadata":{},"outputs":[],"source":["model = load_model('models/chatbot_model.keras')\n","# Modelo encoder para inferencia\n","encoder_model_inf = Model(encoder_inputs, encoder_states)\n","\n","# Modelo decoder para inferencia\n","decoder_state_input_h = Input(shape=(256,))\n","decoder_state_input_c = Input(shape=(256,))\n","decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n","decoder_outputs, state_h, state_c = decoder_lstm(decoder_embedding, initial_state=decoder_states_inputs)\n","decoder_states = [state_h, state_c]\n","decoder_outputs = decoder_dense(decoder_outputs)\n","decoder_model_inf = Model([decoder_inputs] + decoder_states_inputs, [decoder_outputs] + decoder_states)\n","\n","def decode_sequence(input_seq):\n","    states_value = encoder_model_inf.predict(input_seq)\n","    target_seq = np.zeros((1, 1))\n","    target_seq[0, 0] = word2idx_outputs['<sos>']\n","\n","    stop_condition = False\n","    decoded_sentence = ''\n","    while not stop_condition:\n","        output_tokens, h, c = decoder_model_inf.predict([target_seq] + states_value)\n","\n","        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n","        sampled_word = tokenizer_outputs.index_word.get(sampled_token_index, '')\n","\n","        if sampled_word == '<eos>' or len(decoded_sentence) > max_output_len:\n","            stop_condition = True\n","        else:\n","            decoded_sentence += ' ' + sampled_word\n","\n","        target_seq = np.zeros((1, 1))\n","        target_seq[0, 0] = sampled_token_index\n","\n","        states_value = [h, c]\n","\n","    return decoded_sentence\n","\n","\n","def preprocess_sentence(sentence):\n","    # Limpiar la oración de entrada\n","    sentence = clean_text(sentence)\n","    # Convertir la oración en una secuencia de índices\n","    sequence = tokenizer_inputs.texts_to_sequences([sentence])\n","    # Hacer padding a la secuencia para que tenga la longitud máxima de entrada\n","    padded_sequence = pad_sequences(sequence, maxlen=max_input_len)\n","    return padded_sequence\n","\n","def decode_sequence(input_seq):\n","    # Obtener los estados internos del encoder\n","    states_value = encoder_model_inf.predict(input_seq)\n","    \n","    # Generar una secuencia vacía de longitud 1 con el índice del token de inicio\n","    target_seq = np.zeros((1, 1))\n","    target_seq[0, 0] = word2idx_outputs['<sos>']\n","    \n","    decoded_sentence = ''\n","    stop_condition = False\n","    while not stop_condition:\n","        # Obtener las predicciones del decoder\n","        output_tokens, h, c = decoder_model_inf.predict([target_seq] + states_value)\n","        \n","        # Obtener el índice del token con mayor probabilidad\n","        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n","        sampled_word = tokenizer_outputs.index_word.get(sampled_token_index, '')\n","        \n","        if sampled_word == '<eos>' or len(decoded_sentence.split()) > max_output_len:\n","            stop_condition = True\n","        else:\n","            decoded_sentence += ' ' + sampled_word\n","        \n","        # Actualizar la secuencia objetivo (target_seq)\n","        target_seq = np.zeros((1, 1))\n","        target_seq[0, 0] = sampled_token_index\n","        \n","        # Actualizar los estados del decoder\n","        states_value = [h, c]\n","    \n","    return decoded_sentence.strip()\n"]},{"cell_type":"code","execution_count":53,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n","Q: Hello, how are you?\n","A: i m fine i ve got a job\n"]}],"source":["# Probar el modelo con una oración de entrada\n","input_sentence = \"Hello, how are you?\"\n","preprocessed_sentence = preprocess_sentence(input_sentence)\n","decoded_sentence = decode_sequence(preprocessed_sentence)\n","print(f'Q: {input_sentence}')\n","print(f'A: {decoded_sentence}')\n"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"provenance":[]},"kernelspec":{"display_name":"Python 3.10.6 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.6"},"vscode":{"interpreter":{"hash":"916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"}}},"nbformat":4,"nbformat_minor":0}
